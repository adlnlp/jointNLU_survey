{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjePHbyaVkS6"
      },
      "source": [
        "#Sec.0 Overview ðŸ‘€\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZU9Gtr7ZgjL"
      },
      "source": [
        "This notebook is created as the hands-on learning material of the [WWW2023 SLU Tutorial](https://github.com/adlnlp/jointNLU_survey). It aims to provide a basic start-up experience of the joint NLU, more specifically, joint intent classification and slot filling, by simply utilizing the pretrained BERT model (ðŸ‘‰[See Paper for BERT](http://aclanthology.lst.uni-saarland.de/N19-1423.pdf)). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW-n5jikeCpl"
      },
      "source": [
        "Below is an overall structure of this notebook:\n",
        "\n",
        "\n",
        "*   **Sec.0 Overview (Current section):** Articulates the goals and overall structure of this notebook.\n",
        "*   **Sec.1 Let's Try BERT:** Covers the foundation of implementing a pretrained BERT model and fine-tuning it for the intent classification task as a pre-exercise (IntentBERT model), with one of the most common NLU benchmark datasets - SNIPs.\n",
        "*   **Sec.2 BERT for Joint NLU:** Provides the overall procedure of conducting the joint NLU based on the pretrained Bert model by simply modifying the IntentBERT model from Sec.1.\n",
        "*   **Sec.3 Extension: Applying Joint NLU to In-game Toxicity Detection:** Illustrates an interesting application example of joint NLU in the domain of in-game toxicity, utilizing the same jointBERT model on the dual-level annotated CONDA dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFJfhk9NsOb_"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-jY__0fU3X"
      },
      "source": [
        "# Sec.1 Let's Try BERT! ðŸ¤©"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfkCZ6nFkRnN"
      },
      "source": [
        "BERT (ðŸ‘‰[See Paper for BERT](http://aclanthology.lst.uni-saarland.de/N19-1423.pdf)) is a pretrained transformer-based neural network model that can encode the input sequence data into the corresponding contextualized representations which can be utilized for further conducting various targeted tasks. In this section, we will utilize the [`huggingface/transformers`](https://pypi.org/project/transformers/) library from HuggingfaceðŸ¤— to load the pretrained BERT model and fine-tune it for intent classification task only. This is a start-up exercise to get familiar with the BERT model in terms of input preparation, model definition (especially regarding the utilization of the output representation of BERT model for the targeted task), as well as the training/fine-tuning procudure.\n",
        "\n",
        "*Some of the content in this section is modified from this [github lab](https://github.com/m2dsupsdlclass/lectures-labs/blob/master/labs/06_deep_nlp/Transformers_Joint_Intent_Classification_Slot_Filling_rendered.ipynb). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZMsH7kNoNmn"
      },
      "source": [
        "## 1.1 The SNIPS Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYAocMi7pSYX"
      },
      "source": [
        "[SNIPS](https://paperswithcode.com/dataset/snips) is one of the most commonly used Natural Language Understanding benchmark datasets that collects over 16,000 crowdsourced queries distributed among 7 user intents of varying complexity, including: \n",
        "\n",
        "\n",
        "*   SearchCreativeWork (e.g. Find me the I, Robot television show),\n",
        "*   GetWeather (e.g. Is it windy in Boston, MA right now?),\n",
        "*   BookRestaurant (e.g. I want to book a highly rated restaurant in Paris tomorrow night),\n",
        "*   PlayMusic (e.g. Play the last track from BeyoncÃ© off Spotify),\n",
        "*   AddToPlaylist (e.g. Add Diamonds to my roadtrip playlist),\n",
        "*   RateBook (e.g. Give 6 stars to Of Mice and Men),\n",
        "*   SearchScreeningEvent (e.g. Check the showtimes for Wonder Woman in Paris). \n",
        "\n",
        "The training set contains of 13,084 utterances, the validation set and the test set contain 700 utterances each, with 100 queries per intent. The original datasets comes in [YAML format with inline markdown annotations](https://snips-nlu.readthedocs.io/en/latest/dataset.html). For simplicity, we will directly use the preprocessed variant with B-I-O annotations prepared by [Su Zhu](https://github.com/sz128) that is closer to the representation we will predict. \n",
        "\n",
        "\n",
        "Let's first get access to the data files. The following cells will download all the related data needed for this hands-on tutorial, including the dataset and the saved models. \n",
        "\n",
        "\n",
        "NOTES: You need to authenticate via your own Google account in order to download the data below. If you have any issue with downloading the data, you can also access our [shared google drive folder](https://drive.google.com/drive/folders/1ZJ45c9cRfi07Zf6Xust6deMqg3tCyal-?usp=share_link), which contains ALL data needed for this exercise. You can just add a shortcut of this shared folder to your own google drive and then access it via mounting your own google drive in colab.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcx6l7yL8zFv"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate\n",
        "drive = None\n",
        "def authenticate():\n",
        "  global drive\n",
        "  \n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "# Function for Downloading the files\n",
        "def downloadFiles(fileIds):\n",
        "  authenticate()\n",
        "  \n",
        "  for fileId in fileIds:    \n",
        "    \n",
        "    downloaded = drive.CreateFile({\"id\": fileId[1]})\n",
        "    downloaded.GetContentFile(fileId[0])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WP5StuGb8M9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19a891c-5725-4ef7-91a5-a77c4abcec36"
      },
      "source": [
        "# Download data files (It may takes some time :D)\n",
        "downloadFiles([[\"WWW2023-SLU-data-snips.zip\", \"1pElToWUIoFH3gRJvNYoOSuGn8KIIhbbB\"],[\"WWW2023-SLU-model-intentbert.zip\",\"1tIldWrP0tgsB0ZB_grDdoKNTXLY3Hx85\"],[\"WWW2023-SLU-model-jointbert-snips.zip\",\"18UU92t1QhHojkC0g7Kd-_LCWE32D8wC1\"]])\n",
        "!unzip \"WWW2023-SLU-data-snips.zip\" \n",
        "!unzip \"WWW2023-SLU-model-intentbert.zip\" \n",
        "!unzip \"WWW2023-SLU-model-jointbert-snips.zip\"\n",
        "!rm \"WWW2023-SLU-data-snips.zip\" \n",
        "!rm \"WWW2023-SLU-model-intentbert.zip\" \n",
        "!rm \"WWW2023-SLU-model-jointbert-snips.zip\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  WWW2023-SLU-data-snips.zip\n",
            "   creating: WWW2023-SLU-data-snips/WWW2023-SLU-data/\n",
            "   creating: WWW2023-SLU-data-snips/WWW2023-SLU-data/dataset-snips/\n",
            "  inflating: WWW2023-SLU-data-snips/WWW2023-SLU-data/dataset-snips/test  \n",
            "  inflating: WWW2023-SLU-data-snips/WWW2023-SLU-data/dataset-snips/train  \n",
            "  inflating: WWW2023-SLU-data-snips/WWW2023-SLU-data/dataset-snips/valid  \n",
            "  inflating: WWW2023-SLU-data-snips/WWW2023-SLU-data/dataset-snips/vocab.intent  \n",
            "  inflating: WWW2023-SLU-data-snips/WWW2023-SLU-data/dataset-snips/vocab.slot  \n",
            "Archive:  WWW2023-SLU-model-intentbert.zip\n",
            "   creating: WWW2023-SLU-model-intentbert/WWW2023-SLU-data/\n",
            "   creating: WWW2023-SLU-model-intentbert/WWW2023-SLU-data/intentbert10/\n",
            "  inflating: WWW2023-SLU-model-intentbert/WWW2023-SLU-data/intentbert10/checkpoint  \n",
            "  inflating: WWW2023-SLU-model-intentbert/WWW2023-SLU-data/intentbert10/intentbert10.data-00000-of-00001  \n",
            "  inflating: WWW2023-SLU-model-intentbert/WWW2023-SLU-data/intentbert10/intentbert10.index  \n",
            "Archive:  WWW2023-SLU-model-jointbert-snips.zip\n",
            "   creating: WWW2023-SLU-model-jointbert-snips/WWW2023-SLU-data/\n",
            "   creating: WWW2023-SLU-model-jointbert-snips/WWW2023-SLU-data/jointbert-snips30/\n",
            "  inflating: WWW2023-SLU-model-jointbert-snips/WWW2023-SLU-data/jointbert-snips30/checkpoint  \n",
            "  inflating: WWW2023-SLU-model-jointbert-snips/WWW2023-SLU-data/jointbert-snips30/jointbert-snips30.data-00000-of-00001  \n",
            "  inflating: WWW2023-SLU-model-jointbert-snips/WWW2023-SLU-data/jointbert-snips30/jointbert-snips30.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After downloading is completed, you should be able to see three folders in the *Files* structure on the left, which contain the SNIPs dataset and the saved models that we will use later. If you are accessing the data via mounting your own google drive with our shared folder, you can simiply modify the `DATA_DIR` path below to the path to the data folder in your google drive."
      ],
      "metadata": {
        "id": "y2jb8Eaeb1VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the root directory for data resource\n",
        "ROOT_DIR = \"/content\" "
      ],
      "metadata": {
        "id": "9L4kIu5LZX5X"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = ROOT_DIR+'/WWW2023-SLU-data-snips/WWW2023-SLU-data/'\n",
        "MODEL_IB_DIR = ROOT_DIR+'/WWW2023-SLU-model-intentbert/WWW2023-SLU-data/'\n",
        "MODEL_JB_DIR = ROOT_DIR+'/WWW2023-SLU-model-jointbert-snips/WWW2023-SLU-data/'"
      ],
      "metadata": {
        "id": "17JQUJAEQ1Ns"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tImSUr1tDQo"
      },
      "source": [
        "Let's take a look at the first several lines from the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "o4mCRg2UQr1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bdbc9c3-2b42-4049-e823-569f398a230b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Add:O Don:B-entity_name and:I-entity_name Sherri:I-entity_name to:O my:B-playlist_owner Meditate:B-playlist to:I-playlist Sounds:I-playlist of:I-playlist Nature:I-playlist playlist:O <=> AddToPlaylist',\n",
              " 'put:O United:B-entity_name Abominations:I-entity_name onto:O my:B-playlist_owner rare:B-playlist groove:I-playlist playlist:O <=> AddToPlaylist',\n",
              " 'add:O the:O tune:B-music_item by:O misato:B-artist watanabe:I-artist to:O the:O Trapeo:B-playlist playlist:O <=> AddToPlaylist',\n",
              " 'add:O this:O artist:B-music_item to:O my:B-playlist_owner this:B-playlist is:I-playlist miguel:I-playlist bosÃ©:I-playlist playlist:O <=> AddToPlaylist',\n",
              " 'add:O heresy:B-entity_name and:I-entity_name the:I-entity_name hotel:I-entity_name choir:I-entity_name to:O the:O evening:B-playlist acoustic:I-playlist playlist:O <=> AddToPlaylist']"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "from urllib.request import urlretrieve\n",
        "from pathlib import Path\n",
        "\n",
        "lines_train = Path(DATA_DIR+\"dataset-snips/train\").read_text(\"utf-8\").strip().splitlines()\n",
        "lines_train[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezTIAec5jNlq"
      },
      "source": [
        "Some remarks:\n",
        "\n",
        "- The utterance class label, i.e., the intent, for the voice command appears at the end of each line (after the \"<=>\" marker).\n",
        "- Each word-level token is annotated with B-I-O labels using the \":\" separator, i.e., the slots.\n",
        "- B/I/O stand for \"Beginning\" / \"Inside\" / \"Outside\"\n",
        "- For example, in the first line of the training data above, the \"Add:O\" means that the word token \"Add\" is \"Outside (O)\" of any annotation span (slots). The \"Don:B-entity_name\" means that \"Don\" is the \"Beginning (B-)\" of an annotation of the slot type \"entity-name\". The \"and:I-entity_name\" means that \"and\" is \"Inside (I-)\" the previously started annotation of slot type \"entity-name\".\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29HRrBSFtfV_"
      },
      "source": [
        "Now, let's write a parsing function for extracting the key information from each data instance, including the intent (label), textual words, slots (labels), and the utterance length:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "PMzOqdGRWP2u"
      },
      "outputs": [],
      "source": [
        "# Function for parsing each line of data to extract the information for later use\n",
        "def parse_line(line):\n",
        "    utterance_data, intent_label = line.split(\" <=> \")\n",
        "    items = utterance_data.split()\n",
        "    words = [item.rsplit(\":\", 1)[0]for item in items]\n",
        "    word_labels = [item.rsplit(\":\", 1)[1]for item in items]\n",
        "    return {\n",
        "        \"intent_label\": intent_label, # intent (label)\n",
        "        \"words\": \" \".join(words), # textual words\n",
        "        \"word_labels\": \" \".join(word_labels), # slots (labels)\n",
        "        \"length\": len(words), # utterance length\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the parsing function on one of the lines in the data:"
      ],
      "metadata": {
        "id": "Ty-B2m_WnPzA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "-Sg-hZOJXUPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7d882d-863e-4289-88cd-ff3edfc9422c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent_label': 'AddToPlaylist',\n",
              " 'words': 'put United Abominations onto my rare groove playlist',\n",
              " 'word_labels': 'O B-entity_name I-entity_name O B-playlist_owner B-playlist I-playlist O',\n",
              " 'length': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "parse_line(lines_train[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQAwISaFX0zZ"
      },
      "source": [
        "This utterance is a voice command of intent type \"AddToPlaylist\" with three slot annotations:\n",
        "\n",
        "- an entity-name: \"United Abominations\",\n",
        "- a playlist owner: \"my\",\n",
        "- a playlist: \"rare groove\".\n",
        "\n",
        "\n",
        "The end goal of the NLU is to analyse such voice commands and predict:\n",
        "\n",
        "- the intent of the speaker: the sentence level class label (\"AddToPlaylist\"), i.e., the intent classification task;\n",
        "- extract the interesting \"slots\" from the sentence by performing word level classification using the B-I-O tags as target classes, i.e., the slot filling task. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mkBT6IYvYbY"
      },
      "source": [
        "Regarding these two classification-based subtasks, the list of possible classes for the sentence level and the word level classification problems are given as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "q98BNyqOmM1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56983444-e7a9-4fd5-c3f4-e8ea90113b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AddToPlaylist\n",
            "BookRestaurant\n",
            "GetWeather\n",
            "PlayMusic\n",
            "RateBook\n",
            "SearchCreativeWork\n",
            "SearchScreeningEvent\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The list of possible classes for intent classification, 7 intents in total\n",
        "print(Path(DATA_DIR+\"dataset-snips/vocab.intent\").read_text(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "xmJspyNLvosX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dcd8eb-5685-4988-eb97-3bdf2be23d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B-album\n",
            "B-artist\n",
            "B-best_rating\n",
            "B-city\n",
            "B-condition_description\n",
            "B-condition_temperature\n",
            "B-country\n",
            "B-cuisine\n",
            "B-current_location\n",
            "B-entity_name\n",
            "B-facility\n",
            "B-genre\n",
            "B-geographic_poi\n",
            "B-location_name\n",
            "B-movie_name\n",
            "B-movie_type\n",
            "B-music_item\n",
            "B-object_location_type\n",
            "B-object_name\n",
            "B-object_part_of_series_type\n",
            "B-object_select\n",
            "B-object_type\n",
            "B-party_size_description\n",
            "B-party_size_number\n",
            "B-playlist\n",
            "B-playlist_owner\n",
            "B-poi\n",
            "B-rating_unit\n",
            "B-rating_value\n",
            "B-restaurant_name\n",
            "B-restaurant_type\n",
            "B-served_dish\n",
            "B-service\n",
            "B-sort\n",
            "B-spatial_relation\n",
            "B-state\n",
            "B-timeRange\n",
            "B-track\n",
            "B-year\n",
            "I-album\n",
            "I-artist\n",
            "I-city\n",
            "I-country\n",
            "I-cuisine\n",
            "I-current_location\n",
            "I-entity_name\n",
            "I-facility\n",
            "I-genre\n",
            "I-geographic_poi\n",
            "I-location_name\n",
            "I-movie_name\n",
            "I-movie_type\n",
            "I-music_item\n",
            "I-object_location_type\n",
            "I-object_name\n",
            "I-object_part_of_series_type\n",
            "I-object_select\n",
            "I-object_type\n",
            "I-party_size_description\n",
            "I-playlist\n",
            "I-playlist_owner\n",
            "I-poi\n",
            "I-restaurant_name\n",
            "I-restaurant_type\n",
            "I-served_dish\n",
            "I-service\n",
            "I-sort\n",
            "I-spatial_relation\n",
            "I-state\n",
            "I-timeRange\n",
            "I-track\n",
            "O\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The list of possible classes for slot filling, 72 slots in total\n",
        "# PS: The \"POI\" from the \"I-poi\" slot below stands for \"Point of Interest\".\n",
        "print(Path(DATA_DIR+\"dataset-snips/vocab.slot\").read_text(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7g_8JJlv_3O"
      },
      "source": [
        "Now, let's parse all the lines in training set and store the results in pandas DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "YPABk8I2wDCf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "88fdaabf-5ac1-4b1b-81c0-982b8f2dc2ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               intent_label  \\\n",
              "0             AddToPlaylist   \n",
              "1             AddToPlaylist   \n",
              "2             AddToPlaylist   \n",
              "3             AddToPlaylist   \n",
              "4             AddToPlaylist   \n",
              "...                     ...   \n",
              "13079  SearchScreeningEvent   \n",
              "13080  SearchScreeningEvent   \n",
              "13081  SearchScreeningEvent   \n",
              "13082  SearchScreeningEvent   \n",
              "13083  SearchScreeningEvent   \n",
              "\n",
              "                                                   words  \\\n",
              "0      Add Don and Sherri to my Meditate to Sounds of...   \n",
              "1      put United Abominations onto my rare groove pl...   \n",
              "2      add the tune by misato watanabe to the Trapeo ...   \n",
              "3      add this artist to my this is miguel bosÃ© play...   \n",
              "4      add heresy and the hotel choir to the evening ...   \n",
              "...                                                  ...   \n",
              "13079  find a Consolidated Theatres showing The Good ...   \n",
              "13080  where can i see animated movies in the neighbo...   \n",
              "13081        Showtimes for animated movies in the area .   \n",
              "13082  Which animated movies are playing at Megaplex ...   \n",
              "13083             What movie schedules start at sunset ?   \n",
              "\n",
              "                                             word_labels  length  \n",
              "0      O B-entity_name I-entity_name I-entity_name O ...      12  \n",
              "1      O B-entity_name I-entity_name O B-playlist_own...       8  \n",
              "2      O O B-music_item O B-artist I-artist O O B-pla...      10  \n",
              "3      O O B-music_item O B-playlist_owner B-playlist...      10  \n",
              "4      O B-entity_name I-entity_name I-entity_name I-...      11  \n",
              "...                                                  ...     ...  \n",
              "13079  O O B-location_name I-location_name O B-movie_...      10  \n",
              "13080  O O O O B-movie_type I-movie_type B-spatial_re...       9  \n",
              "13081  O O B-movie_type I-movie_type B-spatial_relati...       8  \n",
              "13082  O B-movie_type I-movie_type O O O B-location_n...      11  \n",
              "13083    O B-object_type I-object_type O O B-timeRange O       7  \n",
              "\n",
              "[13084 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39e12e48-553b-4b01-9580-e1addbf144ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intent_label</th>\n",
              "      <th>words</th>\n",
              "      <th>word_labels</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>Add Don and Sherri to my Meditate to Sounds of...</td>\n",
              "      <td>O B-entity_name I-entity_name I-entity_name O ...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>put United Abominations onto my rare groove pl...</td>\n",
              "      <td>O B-entity_name I-entity_name O B-playlist_own...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>add the tune by misato watanabe to the Trapeo ...</td>\n",
              "      <td>O O B-music_item O B-artist I-artist O O B-pla...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>add this artist to my this is miguel bosÃ© play...</td>\n",
              "      <td>O O B-music_item O B-playlist_owner B-playlist...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>add heresy and the hotel choir to the evening ...</td>\n",
              "      <td>O B-entity_name I-entity_name I-entity_name I-...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13079</th>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>find a Consolidated Theatres showing The Good ...</td>\n",
              "      <td>O O B-location_name I-location_name O B-movie_...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13080</th>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>where can i see animated movies in the neighbo...</td>\n",
              "      <td>O O O O B-movie_type I-movie_type B-spatial_re...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13081</th>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>Showtimes for animated movies in the area .</td>\n",
              "      <td>O O B-movie_type I-movie_type B-spatial_relati...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13082</th>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>Which animated movies are playing at Megaplex ...</td>\n",
              "      <td>O B-movie_type I-movie_type O O O B-location_n...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13083</th>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>What movie schedules start at sunset ?</td>\n",
              "      <td>O B-object_type I-object_type O O B-timeRange O</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13084 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39e12e48-553b-4b01-9580-e1addbf144ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39e12e48-553b-4b01-9580-e1addbf144ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39e12e48-553b-4b01-9580-e1addbf144ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "parsed = [parse_line(line) for line in lines_train]\n",
        "\n",
        "# Parse training set\n",
        "df_train = pd.DataFrame([p for p in parsed if p is not None])\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "5yz5pVDewKFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "607f3d69-cbb3-48e2-f1c0-9474de3a408c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      words  word_labels  length\n",
              "intent_label                                    \n",
              "AddToPlaylist          1842         1842    1842\n",
              "BookRestaurant         1873         1873    1873\n",
              "GetWeather             1900         1900    1900\n",
              "PlayMusic              1900         1900    1900\n",
              "RateBook               1856         1856    1856\n",
              "SearchCreativeWork     1854         1854    1854\n",
              "SearchScreeningEvent   1859         1859    1859"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cde9efc-4f40-440e-9c77-b7f6c2a8f9bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>word_labels</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intent_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AddToPlaylist</th>\n",
              "      <td>1842</td>\n",
              "      <td>1842</td>\n",
              "      <td>1842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BookRestaurant</th>\n",
              "      <td>1873</td>\n",
              "      <td>1873</td>\n",
              "      <td>1873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GetWeather</th>\n",
              "      <td>1900</td>\n",
              "      <td>1900</td>\n",
              "      <td>1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PlayMusic</th>\n",
              "      <td>1900</td>\n",
              "      <td>1900</td>\n",
              "      <td>1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RateBook</th>\n",
              "      <td>1856</td>\n",
              "      <td>1856</td>\n",
              "      <td>1856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SearchCreativeWork</th>\n",
              "      <td>1854</td>\n",
              "      <td>1854</td>\n",
              "      <td>1854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SearchScreeningEvent</th>\n",
              "      <td>1859</td>\n",
              "      <td>1859</td>\n",
              "      <td>1859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cde9efc-4f40-440e-9c77-b7f6c2a8f9bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cde9efc-4f40-440e-9c77-b7f6c2a8f9bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cde9efc-4f40-440e-9c77-b7f6c2a8f9bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "# Intent label distribution, it can be seen that the training set is almost evenly distributed regarding the intents \n",
        "df_train.groupby(\"intent_label\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "NL96VYgEwe_f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "f67bc3d0-6700-4825-9ae0-144c33e20259"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'length'}>]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Query length distribution\n",
        "df_train.hist(\"length\", bins=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then let's do the same to the validation and test set for later use."
      ],
      "metadata": {
        "id": "vacEBWwNOYxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "Dfhu8nkOwqlX"
      },
      "outputs": [],
      "source": [
        "# Similarly, read and parse the validation and test set and and store the results in pandas DataFrames\n",
        "lines_valid = Path(DATA_DIR+\"dataset-snips/valid\").read_text(\"utf-8\").strip().splitlines()\n",
        "lines_test = Path(DATA_DIR+\"dataset-snips/test\").read_text(\"utf-8\").strip().splitlines()\n",
        "\n",
        "df_valid = pd.DataFrame([parse_line(line) for line in lines_valid])\n",
        "df_test = pd.DataFrame([parse_line(line) for line in lines_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg-IBxbaw0vK"
      },
      "source": [
        "## 1.2 Pre-exercise: BERT for Intent Classiication "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D08sPBcYxW4Q"
      },
      "source": [
        "To get familiar with how to utilize the pretrained BERT model for fine-tuning the targeted tasks, in terms of input preparation, model definition with task adaptation (i.e., utilization of the BERT output representation for final task), as well as the procedure of training/fine-tuning, let's ignore the slot filling task for now and only focus on the sentence-level intent classification. We will use the [`huggingface/transformers`](https://pypi.org/project/transformers/2.11.0/) package that provides both TF2/Keras and Pytorch APIs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiJH1vSgE8ET",
        "outputId": "d871b850-5da5-4ed1-92be-27feadb13f97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osHFz7-bzb-5"
      },
      "source": [
        "### The BERT Tokenizer\n",
        "\n",
        "First, let's load a pre-trained tokenizer and test it on a sample sentence from the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "f7SNCmgJyazT"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# We're using the Bert tokenizer for the 'bert-base-cased' pretrained model, which is based on WordPiece.\n",
        "# More details of the 'bert-base-case' model description can be found from https://huggingface.co/bert-base-cased\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name) # It download the vocabulary from huggingface.co and cache"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get a sample sentence from the training set and try with the Bert tokenizer we just constructed."
      ],
      "metadata": {
        "id": "E6xwD7CwX9yJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "Jd7VLodv0Tc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "76d4884c-b26f-4c60-9004-8a0dad78fa9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Add Don and Sherri to my Meditate to Sounds of Nature playlist'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "# Get a sample sentence\n",
        "first_sentence = df_train.iloc[0][\"words\"]\n",
        "first_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `tokenizer.tokenize()` function can split(tokenize) the sentence into tokens based on the Bert tokenizer vocabulary. As can be seen that BERT uses subword tokens so the length of the tokenized sentence is likely to be larger than the number of words in the sentence."
      ],
      "metadata": {
        "id": "cisq9Zr4YG8P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "ub42BmUS0YCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a6c9e3-d711-4cf5-897f-d4fd71dcbc4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ad',\n",
              " '##d',\n",
              " 'Don',\n",
              " 'and',\n",
              " 'She',\n",
              " '##rri',\n",
              " 'to',\n",
              " 'my',\n",
              " 'Me',\n",
              " '##dit',\n",
              " '##ate',\n",
              " 'to',\n",
              " 'Sounds',\n",
              " 'of',\n",
              " 'Nature',\n",
              " 'play',\n",
              " '##list']"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "# tokenizer.tokenize() tokenizes the input sencence into sub-words based tokens\n",
        "tokenizer.tokenize(first_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV0nkrwDvVlc"
      },
      "source": [
        "\n",
        "The `tokenizer.encode()` function can convert the utterance directly into the corresponding token ids. Each token id is a unique integer id of the corresponding tokens in the vocabulary that makes it fast to lookup the right column in the input layer token embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "RwsN-er9nsOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae47c89-aef2-40f4-efcc-eba3b53574bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 24930,\n",
              " 1181,\n",
              " 1790,\n",
              " 1105,\n",
              " 1153,\n",
              " 14791,\n",
              " 1106,\n",
              " 1139,\n",
              " 2508,\n",
              " 17903,\n",
              " 2193,\n",
              " 1106,\n",
              " 10560,\n",
              " 1104,\n",
              " 7009,\n",
              " 1505,\n",
              " 7276,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "# tokenizer.encode() encodes the input sentence into the BERT-vocab-based integers, which aligns with the tokenized sub-words\n",
        "# Comparing with the tokenized sequence above, two more tokens are included, which are the two special tokens '[CLS]' and '[SEP]' \n",
        "# from the BERT input format (See following cells for more detail)\n",
        "tokenizer.encode(first_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e80rCfLZo0ms"
      },
      "source": [
        "The mapping can be inspected in the `tokenizer.vocab` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "CnIQq0qD4aHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5c05bb-034b-4b03-dd9c-3ad48402a005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('[CLS]', 101)\n",
            "('Ad', 24930)\n",
            "('##d', 1181)\n",
            "...\n",
            "('[SEP]', 102)\n"
          ]
        }
      ],
      "source": [
        "bert_vocab_items = list(tokenizer.vocab.items())\n",
        "print(bert_vocab_items[101])\n",
        "print(bert_vocab_items[24930])\n",
        "print(bert_vocab_items[1181])\n",
        "print(\"...\")\n",
        "print(bert_vocab_items[102])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "UCOHf8d0whpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d30b6d-0d46-4d95-b784-61db5b64419b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28996"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIG9wZqF0nV6"
      },
      "source": [
        "We can also easily decode the encoded integer back to the original text using the `tokenizer.decode()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "UiC-ch5O0l_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "54e66311-8a48-46af-ab10-115cc93c7dce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] Add Don and Sherri to my Meditate to Sounds of Nature playlist [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "# tokenizer.decode() converts the BERT-vocab-based integers back to the original text. \n",
        "# It can be seen that the sub-word will be automatically assembled as the single word from the original text.\n",
        "tokenizer.decode(tokenizer.encode(first_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXvGt8fAmW6o"
      },
      "source": [
        "Remarks:\n",
        "\n",
        "- The `[CLS]` and `[SEP]` are the two special tokens applied by BERT\n",
        "- The first token `[CLS]` is prepended at the beginning of the sequence and is used by the pre-training task for sequence classification, i.e., it aims to represent the global semantic representation of the whole sequence. In the implementation of Bert, it uses the representation of `[CLS]` token passed through a pooler layer, which contains a dense layer with a tanh activation, for sequence-level classification. It is called as *pooled output*.\n",
        "- Here we want to use BERT to compute a global representation of a single voice command at a time. Thus, we could reuse the *pooled output* representation of the `[CLS]` token for sequence classification. Alternatively we can also pool the representations of all the tokens of the voice command (e.g. global average) and use that as the input of the final sequence classification layer.\n",
        "- The last token `[SEP]` is a separator for the pre-training task that classifies if a pair of input sentences are consecutive in a corpus or not (next sentence prediction).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKOfepFGnja_"
      },
      "source": [
        "To perform transfer learning (i.e., conduct fine-tuning), we will need to work with padded sequences so they all have the same sizes. The histogram below shows that after tokenization, 43 tokens are enough to represent all the voice commands in the training set. Thus, we can just set the max length to 45 later for encoding the batch inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "HDRfHq45uXtE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "ca5c587a-dc7a-4eb8-a2a8-67cc5eebccba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check the sequence length distribution after encoding into the BERT-formatted tokenized sequence\n",
        "train_sequence_lengths = [len(tokenizer.encode(text))\n",
        "                          for text in df_train[\"words\"]]\n",
        "plt.hist(train_sequence_lengths, bins=30)\n",
        "plt.title(f\"max sequence length: {max(train_sequence_lengths)}\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q399LhkCjCa8"
      },
      "source": [
        "### Encoding the Dataset with the Tokenizer\n",
        "\n",
        "Let's now encode the full train / validation and test sets with our tokenizer to get padded numpy arrays of integers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "KI7fXQKmpQFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0efce04f-45a2-42cf-ff68-28adf499a2a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101, 24930,  1181, ...,     0,     0,     0],\n",
              "       [  101,  1508,  1244, ...,     0,     0,     0],\n",
              "       [  101,  5194,  1103, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101, 27640,  1116, ...,     0,     0,     0],\n",
              "       [  101,  5979,  6608, ...,     0,     0,     0],\n",
              "       [  101,  1327,  2523, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def encode_dataset(tokenizer, text_sequences, max_length):\n",
        "    # initialize the zero-valued array with the shape of (data size, max sequence length)\n",
        "    # so that we can just fill in the encoded tokens into it, letting those 0 values that are not replaced with encoded tokens be the padding tokens\n",
        "    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n",
        "                         dtype=np.int32)\n",
        "    \n",
        "    for i, text_sequence in enumerate(text_sequences):\n",
        "        encoded = tokenizer.encode(text_sequence) # encode the sequence into Bert-formatted integers\n",
        "        token_ids[i, 0:len(encoded)] = encoded # fill in the encoded integers into the initialized zero-valued array\n",
        "    attention_masks = (token_ids != 0).astype(np.int32) # create the attention mask, see the details in the follow-up cell\n",
        "    return {\"input_ids\": token_ids, \"attention_mask\": attention_masks}\n",
        "\n",
        "# Encode the training set\n",
        "# Here we use 45 as our max sequence length\n",
        "encoded_train = encode_dataset(tokenizer, df_train[\"words\"], 45)\n",
        "\n",
        "# The 'input_ids' is the indices of input sequence tokens in the vocabulary.\n",
        "# The converted result is a padded numpy arrays of integers which has shape (data_size, max_length), i.e., (13084, 45) in this case.\n",
        "# As you can see all the 0s in the end represent the padding tokens\n",
        "encoded_train[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "NdlcCoh15sQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d275238d-c5fd-4e79-8a9e-f7f49924a0ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "# The 'attention mask' is to avoid performing attention on padding token indices\n",
        "# In the attention_mask, 1 indicates the real word in the tokenized sentences (NOT masked) while 0 means paddings (masked)\n",
        "encoded_train[\"attention_mask\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "FgP6YDCh5_Yp"
      },
      "outputs": [],
      "source": [
        "# Similarly, let's encode validation and test set\n",
        "encoded_valid = encode_dataset(tokenizer, df_valid[\"words\"], 45)\n",
        "encoded_test = encode_dataset(tokenizer, df_test[\"words\"], 45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIgGo8ECtvfy"
      },
      "source": [
        "### Encoding the Intent Classification Targets\n",
        "\n",
        "Now, let's prepare the target labels for the intent detection. To do so we build a simple mapping from the auxiliary files that store the intents:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intent_names = Path(DATA_DIR+\"dataset-snips/vocab.intent\").read_text(\"utf-8\").split()\n",
        "intent_map = dict((label, idx) for idx, label in enumerate(intent_names))\n",
        "# It can map the 7 intents to the corresponding unique integer/index\n",
        "intent_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y20FmNsoWftT",
        "outputId": "bd45d7d4-fb0a-433d-ca95-7ae2725df680"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AddToPlaylist': 0,\n",
              " 'BookRestaurant': 1,\n",
              " 'GetWeather': 2,\n",
              " 'PlayMusic': 3,\n",
              " 'RateBook': 4,\n",
              " 'SearchCreativeWork': 5,\n",
              " 'SearchScreeningEvent': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can convert the actual intent labels of each data instance into the corresponding integer/index using the mapping."
      ],
      "metadata": {
        "id": "uvrK6QU2hmqP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "wFjLpaFxxQk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4834ae3-8a1d-48a3-ca51-bafa9ecb2f2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 6, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "# Get the mapped intent integer labels for the training set\n",
        "intent_train = df_train[\"intent_label\"].map(intent_map).values\n",
        "intent_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "aRbvVXuPndoN"
      },
      "outputs": [],
      "source": [
        "# Similarly, get the mapped intent integer labels for the validation and test sets\n",
        "intent_valid = df_valid[\"intent_label\"].map(intent_map).values\n",
        "intent_test = df_test[\"intent_label\"].map(intent_map).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5TuDZR26jwq"
      },
      "source": [
        "### Pretrained BERT model and its Output?\n",
        "\n",
        "So far, we've done the bert-formatted input praperation (including the input sequence data encoding and the intent labels conversion). Now, let's move to the modeling part. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7EDL_dj7hIr"
      },
      "source": [
        "First, let's try loading a pretrained BERT model using the [huggingface transformers](https://pypi.org/project/transformers/2.11.0/) package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "73ZrDDm-0wYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76af097c-e446-480d-9763-940c67e328e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108310272 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108,310,272\n",
            "Trainable params: 108,310,272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "# We're using the 'bert-base-cased' pretrained model\n",
        "# It instantiates the Bert model and loads the pretrained weights for the 'bert-base-cased' model\n",
        "base_bert_model = TFAutoModel.from_pretrained(\"bert-base-cased\")\n",
        "base_bert_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ4vrlSg8ALZ"
      },
      "source": [
        "Let's try to feed some data into the pretrained BERT model and see what the output representation looks like."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's just use the encoded validation data\n",
        "encoded_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qwkDkRcWkWf",
        "outputId": "c97eb3b9-70b0-4b31-8c2d-c3d876840f5a"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': array([[  101,   142, 13894, ...,     0,     0,     0],\n",
              "        [  101,  2825,   179, ...,     0,     0,     0],\n",
              "        [  101, 24930,  1181, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  1525,   170, ...,     0,     0,     0],\n",
              "        [  101,  4630,  1143, ...,     0,     0,     0],\n",
              "        [  101,  1327,  1159, ...,     0,     0,     0]], dtype=int32),\n",
              " 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "duDb_wRd99Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1d8f34-8e37-4b82-80a9-de566b4ed1e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "# Feed them into the BERT model and get the model output\n",
        "outputs = base_bert_model(encoded_valid)\n",
        "\n",
        "# As you can see, the returned output has two elements\n",
        "len(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkwN4INi8eSh"
      },
      "source": [
        "The **first output** of the BERT model is a tensor with shape: `(batch_size, seq_len, output_dim)` which computes **features for each token in the input sequence** (Yes, we will use it for the slot filling later!):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "0PoQyA_A7CS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ccec87c-ee9f-44e0-f061-02633af03dc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([700, 45, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "# As is shown in the log below, the first output shape is (700, 45, 768), 700 refers to the data size of the validation set, \n",
        "# 45 is the sequence length, 768 is the predefined hidden (feature) size of the pretrained Bert_base model\n",
        "outputs[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxjU9Wpi8vyM"
      },
      "source": [
        "The **second output** of the BERT model is a tensor with shape `(batch_size, output_dim)` which is the vector representation of the special token `[CLS]`. This vector is typically used as a **pooled representation for the sequence as a whole**. This will be used as the features of our Intent classifier for now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "gbg9Yd6MTlQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ebc41b-b46f-4474-bb7d-5667e27e7941"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([700, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "# Again, 700 refers to the data size of the validation set, 768 is the predefined hidden (feature) size of the pretrained Bert_base model\n",
        "outputs[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkS7B9d3_Cp7"
      },
      "source": [
        "### The IntentBert!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jpGypf__exk"
      },
      "source": [
        "Now, let's define the BERT model for intent classification! We will use the `self.bert` pre-trained model in the `call` method and only consider the pooled features (the second output of the Bert model) while ignoring the token-wise sequence features (the first output of the Bert model) for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "5MHs4tDuhVe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b63c3f-4020-400d-c68f-22c19958b6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings. filterwarnings('ignore')\n",
        "from transformers import TFAutoModel\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "\n",
        "\n",
        "class IntentBert(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, intent_num_labels=None, model_name=\"bert-base-cased\",\n",
        "                 dropout_prob=0.1):\n",
        "        super().__init__(name=\"joint_intent_slot\")\n",
        "        self.bert = TFAutoModel.from_pretrained(model_name)\n",
        "        self.dropout = Dropout(dropout_prob)\n",
        "\n",
        "        # Use the default linear activation (no softmax) to compute logits.\n",
        "        # The softmax normalization will be computed in the loss function instead of the model itself.\n",
        "        self.intent_classifier = Dense(intent_num_labels)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        outputs = self.bert(inputs, training=training)\n",
        "        pooled_output = outputs[1]\n",
        "        # only consider the pooled_output for intent classification\n",
        "        # Recap: the pooled_output is the (second) output of the Bert model, which is the representation of the [CLS] token passed through a pooler layer, which contains the dense layer with a tanh activation \n",
        "        # The pooled_output can serve as the global representation of the sequence\n",
        "        pooled_output = self.dropout(pooled_output, training=training)\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "        return intent_logits\n",
        "\n",
        "# Initialize the IntentBert model\n",
        "intent_model = IntentBert(intent_num_labels=len(intent_map))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_QgWEnBi9lE"
      },
      "source": [
        "As we can see our classification model outputs logits (i.e. that is unnormalized real numbers output from a log function) instead of probabilities. Here we configure the loss function by setting the `from_logits=True` (`SparseCategoricalCrossentropy(from_logits=True)`) accordingly. By doing this, the loss function accepts the unnormalized logits directly and will apply the softmax normalization layer accordingly when calculating the loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "1GLdN82steHF"
      },
      "outputs": [],
      "source": [
        "# Configure the training settings\n",
        "intent_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=3e-5, epsilon=1e-08),\n",
        "                     loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "                     metrics=[SparseCategoricalAccuracy('accuracy')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "9bXYT1U4tKtW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6b74e6-29f6-4584-f0f9-f6bfd8dc6990"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f29e948a3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "# Train IntentBert model by fine-tuning the pretrained Bert model \n",
        "#history = intent_model.fit(encoded_train, intent_train, epochs=10, batch_size=128,validation_data=(encoded_valid, intent_valid))  \n",
        "\n",
        "# To save the running time, here we will directly load the weights of the model that we've already trained over 10 epochs for demonstration\n",
        "# If you want to train it yourself, you can uncomment the above code for training using .fit() above - make sure you are using the GPU runtime for faster training\n",
        "intent_model.load_weights(MODEL_IB_DIR+'intentbert10/intentbert10')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjVuRqSOAodb"
      },
      "source": [
        "To demonstrate the 'ability' of the trained IntentBert model for intent classification, let's define a `detect_intent()` function that can classify any input text query into one of the focused intents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "jlVUzCYGAoFk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a8f780d4-ffb9-4b72-9ea9-bb369a297ce6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BookRestaurant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "def detect_intent(text, tokenizer, model, intent_names):\n",
        "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # make batch_size = 1\n",
        "    class_id = model(inputs).numpy().argmax(axis=1)[0]\n",
        "    return intent_names[class_id]\n",
        "\n",
        "\n",
        "detect_intent(\"Book a table for two at La Tour d'Argent for Friday night.\",\n",
        "         tokenizer, intent_model, intent_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "lEs6TJQYBLFk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "42a69339-d60a-46e7-9216-d49e0e1baaca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PlayMusic'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "detect_intent(\"I would like to listen to Anima by Thom Yorke.\",\n",
        "         tokenizer, intent_model, intent_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "y5oRJ9TRBM-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6aa9518d-ef81-40fc-a4a3-2d73b836a859"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GetWeather'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "detect_intent(\"Will it snow tomorrow in Saclay?\",\n",
        "         tokenizer, intent_model, intent_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "tfaURgdsBPFv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "16e35322-4840-47e1-d074-eb8e21764808"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SearchScreeningEvent'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "detect_intent(\"Where can I see to the last Star Wars near OdÃ©on tonight?\",\n",
        "         tokenizer, intent_model, intent_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGur-AHzBX7s"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgr-hMIcfb8c"
      },
      "source": [
        "# Sec.2 Bert for Joint NLU ðŸ’¬"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYDitfvUBi0d"
      },
      "source": [
        "In Sec.1, we've practised how to utilize the output representation of the pretrained BERT model to do the intent classification task, more specifically, utilizing the second element of the returned model output, which is the pooled representation for the sequence as a whole. Now, let's move on to our final NLU task goal regarding both intent classification and slot filling.\n",
        "\n",
        "*NOTE: The following code cells require the running of previous sections!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YsRCStlIbuH"
      },
      "source": [
        "### Encoding the Slot Filling Targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amAltjH8EAyE"
      },
      "source": [
        "In the previous sections, we've already encoded the input sequences and the intent labels. To do the joint NLU, we will also prepare the slot labels in order to perform word level (or token level) classification of the BIO slots.\n",
        "\n",
        "\n",
        "Let's first load the list of possible word token labels and augment it with an additional padding label to be able to ignore special tokens, i.e., this padding label serves as a general ground truth label for all the special tokens such as the `[CLS]`/`[SEP]` and the `padding` tokens that are out of our interests for prediction so that we can easily ignore them later when evaluating our model prediction performance. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "lIp3nMfjFfp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fdac9a-a038-4426-866a-6a2d7bf1abc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0,\n",
              " 'B-album': 1,\n",
              " 'B-artist': 2,\n",
              " 'B-best_rating': 3,\n",
              " 'B-city': 4,\n",
              " 'B-condition_description': 5,\n",
              " 'B-condition_temperature': 6,\n",
              " 'B-country': 7,\n",
              " 'B-cuisine': 8,\n",
              " 'B-current_location': 9,\n",
              " 'B-entity_name': 10,\n",
              " 'B-facility': 11,\n",
              " 'B-genre': 12,\n",
              " 'B-geographic_poi': 13,\n",
              " 'B-location_name': 14,\n",
              " 'B-movie_name': 15,\n",
              " 'B-movie_type': 16,\n",
              " 'B-music_item': 17,\n",
              " 'B-object_location_type': 18,\n",
              " 'B-object_name': 19,\n",
              " 'B-object_part_of_series_type': 20,\n",
              " 'B-object_select': 21,\n",
              " 'B-object_type': 22,\n",
              " 'B-party_size_description': 23,\n",
              " 'B-party_size_number': 24,\n",
              " 'B-playlist': 25,\n",
              " 'B-playlist_owner': 26,\n",
              " 'B-poi': 27,\n",
              " 'B-rating_unit': 28,\n",
              " 'B-rating_value': 29,\n",
              " 'B-restaurant_name': 30,\n",
              " 'B-restaurant_type': 31,\n",
              " 'B-served_dish': 32,\n",
              " 'B-service': 33,\n",
              " 'B-sort': 34,\n",
              " 'B-spatial_relation': 35,\n",
              " 'B-state': 36,\n",
              " 'B-timeRange': 37,\n",
              " 'B-track': 38,\n",
              " 'B-year': 39,\n",
              " 'I-album': 40,\n",
              " 'I-artist': 41,\n",
              " 'I-city': 42,\n",
              " 'I-country': 43,\n",
              " 'I-cuisine': 44,\n",
              " 'I-current_location': 45,\n",
              " 'I-entity_name': 46,\n",
              " 'I-facility': 47,\n",
              " 'I-genre': 48,\n",
              " 'I-geographic_poi': 49,\n",
              " 'I-location_name': 50,\n",
              " 'I-movie_name': 51,\n",
              " 'I-movie_type': 52,\n",
              " 'I-music_item': 53,\n",
              " 'I-object_location_type': 54,\n",
              " 'I-object_name': 55,\n",
              " 'I-object_part_of_series_type': 56,\n",
              " 'I-object_select': 57,\n",
              " 'I-object_type': 58,\n",
              " 'I-party_size_description': 59,\n",
              " 'I-playlist': 60,\n",
              " 'I-playlist_owner': 61,\n",
              " 'I-poi': 62,\n",
              " 'I-restaurant_name': 63,\n",
              " 'I-restaurant_type': 64,\n",
              " 'I-served_dish': 65,\n",
              " 'I-service': 66,\n",
              " 'I-sort': 67,\n",
              " 'I-spatial_relation': 68,\n",
              " 'I-state': 69,\n",
              " 'I-timeRange': 70,\n",
              " 'I-track': 71,\n",
              " 'O': 72}"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "slot_names = [\"[PAD]\"]\n",
        "slot_names += Path(DATA_DIR+\"dataset-snips/vocab.slot\").read_text(\"utf-8\").strip().splitlines()\n",
        "slot_map = {}\n",
        "for label in slot_names:\n",
        "    slot_map[label] = len(slot_map)\n",
        "# We add the special slot label [PAD] with the corresponding index of 0\n",
        "slot_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8CX6LxYmhRh"
      },
      "source": [
        "Since we have word level tags but BERT uses a wordpiece (sub-word) tokenizer, we need to align the BIO labels with the BERT tokens.\n",
        "\n",
        "The following function generates token-aligned integer labels from the BIO word-level annotations. In particular, if a specific word is tokenized into subwords, we expand its label for all the subword tokens of that word while taking care of using \"B-\" labels only for the first token and then use \"I-\" for the matching slot type for subsequent tokens of the same word. For example, assume:\n",
        "\n",
        "original text query: \"... x x x word1 word2 word3 word4 word5 ...\" \n",
        "\n",
        "original slot labels: \"... O O O B-city I-city B-state I-state I-state ...\"\n",
        "\n",
        "Then, assume after encoding, the sub-token-based text query:\n",
        "\n",
        "encoded text query (tokenized): \"..., x, x, x, word1-subword1, word1-subword2, word2, word3, word4-subword1, word4-subword2, word5, ...\"\n",
        "\n",
        "Then, the encoded slot labels would be:\n",
        "\n",
        "encoded slot labels: \"..., x, x, x, B-city, I-city, I-city, B-state, I-state, I-state, I-state, ...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "s0Lr5aekGDJ-"
      },
      "outputs": [],
      "source": [
        "def encode_token_labels(text_sequences, slot_names, tokenizer, slot_map,\n",
        "                        max_length):\n",
        "    # initialize the zero-valued array with the same shape of the encoded input data\n",
        "    encoded = np.zeros(shape=(len(text_sequences), max_length), dtype=np.int32)\n",
        "    \n",
        "    # then try to fill in the corresponding mapped slot integer label that align with the encoded input tokens\n",
        "    for i, (text_sequence, word_labels) in enumerate(\n",
        "            zip(text_sequences, slot_names)):\n",
        "        encoded_labels = []\n",
        "        for word, word_label in zip(text_sequence.split(), word_labels.split()):\n",
        "            tokens = tokenizer.tokenize(word) # tokenize each word\n",
        "            encoded_labels.append(slot_map[word_label]) # record the original slot label (mapped integer) for the current word \n",
        "            expand_label = word_label.replace(\"B-\", \"I-\") # then replace the B- with I- (if it is B- type) since it (I- label) will be used as the labels for the subsequent sub-tokens (if there are any sub-tokens). \n",
        "            if not expand_label in slot_map:\n",
        "                expand_label = word_label\n",
        "            encoded_labels.extend([slot_map[expand_label]] * (len(tokens) - 1)) # if there are subsequent sub-tokens, record the I- type slots (mapped integer) as their ground truth labels\n",
        "        encoded[i, 1:len(encoded_labels) + 1] = encoded_labels # fill in the recorded slot labels into the initialized zero-valued array\n",
        "    # Note that the O slot labels will be the same for sub-tokens \n",
        "    # And the slot labels for all the special tokens such as the first token [CLS] and the padding tokens in the end of the sequence will still be 0, which aligns with the [pad] slot label we added\n",
        "    return encoded\n",
        "\n",
        "\n",
        "# Now encode the slots for training/validation/test set\n",
        "slot_train = encode_token_labels(\n",
        "    df_train[\"words\"], df_train[\"word_labels\"], tokenizer, slot_map, 45)\n",
        "slot_valid = encode_token_labels(\n",
        "    df_valid[\"words\"], df_valid[\"word_labels\"], tokenizer, slot_map, 45)\n",
        "slot_test = encode_token_labels(\n",
        "    df_test[\"words\"], df_test[\"word_labels\"], tokenizer, slot_map, 45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "9N1treFMWk6G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0af092-ffd6-40ae-fc3e-611b544e096d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 72, 72, 10, 46, 46, 46, 72, 26, 25, 60, 60, 60, 60, 60, 60, 72,\n",
              "       72,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "# Let's take a look at the encoded slot labels for the first data in the training set\n",
        "# All the zero values indicates the padding slot (label) for all the special tokens including [CLS]/[SEP] and padding tokens\n",
        "slot_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "YPxRpB5044QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c730e073-9896-4a4c-b011-b366ccf2db62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  2, 41, 41, 72, 72, 72, 26, 25, 72, 72,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "slot_valid[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUOBE-NDIPM9"
      },
      "source": [
        "Note that the special tokens such as \"[PAD]\" and \"[SEP]\" and all padded positions receive a 0 label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKco4O3nIk6t"
      },
      "source": [
        "### Finally! The JointBert!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXev686pJC5X"
      },
      "source": [
        "Now, we've had every single piece of data prepared with SNIPS (i.e., the encoded input sequences and both intent and slot labels)! Let's simply modify based on the IntentBert model from Sec.1 and convert it to our JointBert via also utilizing the first element of the returned Bert model output ðŸ˜‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cQuCTbMJ6vc"
      },
      "source": [
        "The JointBert for intent classification and slot filling is a simple replication of the model of [Joint Bert](https://arxiv.org/pdf/1902.10909.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "2Jr_SPFQJwG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69be665a-76f8-4564-e1ca-ab380e1a021c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings. filterwarnings('ignore')\n",
        "from transformers import TFAutoModel\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "\n",
        "class JointBert(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n",
        "                 model_name=\"bert-base-cased\", dropout_prob=0.1):\n",
        "        super().__init__(name=\"joint_intent_slot\")\n",
        "        self.bert = TFAutoModel.from_pretrained(model_name)\n",
        "        self.dropout = Dropout(dropout_prob)\n",
        "        self.intent_classifier = Dense(intent_num_labels,\n",
        "                                       name=\"intent_classifier\")\n",
        "        self.slot_classifier = Dense(slot_num_labels,\n",
        "                                     name=\"slot_classifier\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        outputs = self.bert(inputs, training=training)\n",
        "        sequence_output = outputs[0]\n",
        "        pooled_output = outputs[1]\n",
        "        # Recap: The first output (sequence_output) of the main BERT layer has shape: (batch_size, max_length, output_dim)\n",
        "        # This will be used for slot filling\n",
        "        sequence_output = self.dropout(sequence_output, training=training)\n",
        "        slot_logits = self.slot_classifier(sequence_output)\n",
        "\n",
        "        # Recap: The second output (pooled_output) of the main BERT layer has shape: (batch_size, output_dim) \n",
        "        # It is the output representation of the [CLS] token passed through a pooler layer, which contains the dense layer with a tanh activation \n",
        "        # The pooled_output can serve as the global representation of the sequence\n",
        "        # This will be used for intent classification, same as what we did in sec.1 for the IntentBert\n",
        "        pooled_output = self.dropout(pooled_output, training=training)\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return slot_logits, intent_logits\n",
        "\n",
        "# Initialize the JointBert model\n",
        "joint_model = JointBert(\n",
        "    intent_num_labels=len(intent_map), slot_num_labels=len(slot_map))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "Z47pxSRwKit2"
      },
      "outputs": [],
      "source": [
        "# Configure the training settings\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
        "losses = [SparseCategoricalCrossentropy(from_logits=True),\n",
        "          SparseCategoricalCrossentropy(from_logits=True)]\n",
        "metrics = [SparseCategoricalAccuracy('accuracy')]\n",
        "joint_model.compile(optimizer=opt, loss=losses, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "DieDfCPiKp_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54685bb0-4067-41a5-9c6b-c66c6e0299a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f274c306640>"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ],
      "source": [
        "# Train JointBert model by fine-tuning the pretrained Bert model \n",
        "#history = joint_model.fit(encoded_train, (slot_train, intent_train),validation_data=(encoded_valid, (slot_valid, intent_valid)),epochs=30, batch_size=128)\n",
        "\n",
        "# To save the running time, here we will directly load the weights of the model that we've already trained over 30 epochs for demonstration\n",
        "# If you want to train it yourself, you can uncomment the above code for training using .fit() above - make sure you are using the GPU runtime for faster training\n",
        "joint_model.load_weights(MODEL_JB_DIR+'jointbert-snips30/jointbert-snips30')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6u2BlOoK7R3"
      },
      "source": [
        "Again, to demonstrate the 'ability' of the trained JointBert model for both intent classification and slot filling, let's define a *conduct_nlu()* function that can classify any input text query into one of the focused intents as well as the corresponding slots for each token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "Ve6Sppl4LOfT"
      },
      "outputs": [],
      "source": [
        "def conduct_nlu(text, tokenizer, model, intent_names, slot_names):\n",
        "    inputs = tf.constant(tokenizer.encode(text))[None, :]  # make batch_size = 1\n",
        "    outputs = model(inputs)\n",
        "    slot_logits, intent_logits = outputs\n",
        "    slot_ids = slot_logits.numpy().argmax(axis=-1)[0, 1:-1]\n",
        "    intent_id = intent_logits.numpy().argmax(axis=-1)[0]\n",
        "    print(\"## Intent:\", intent_names[intent_id])\n",
        "    print(\"## Slots:\")\n",
        "    for token, slot_id in zip(tokenizer.tokenize(text), slot_ids):\n",
        "        print(f\"{token:>10} : {slot_names[slot_id]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conduct_nlu(\"Book a table for two at Le Ritz for Friday night!\",\n",
        "                 tokenizer, joint_model, intent_names, slot_names)"
      ],
      "metadata": {
        "id": "3gXr4WXEvyTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d82a659-2b08-485e-cf39-b0faefecd62b"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Intent: BookRestaurant\n",
            "## Slots:\n",
            "      Book : O\n",
            "         a : O\n",
            "     table : O\n",
            "       for : O\n",
            "       two : B-party_size_number\n",
            "        at : O\n",
            "        Le : B-restaurant_name\n",
            "         R : I-restaurant_name\n",
            "     ##itz : I-restaurant_name\n",
            "       for : O\n",
            "    Friday : B-timeRange\n",
            "     night : I-timeRange\n",
            "         ! : O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conduct_nlu(\"Will it snow tomorrow in Saclay?\",\n",
        "                 tokenizer, joint_model, intent_names, slot_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4pc270oJIaC",
        "outputId": "396561a8-e220-463e-df69-a4defaaa8024"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Intent: GetWeather\n",
            "## Slots:\n",
            "      Will : O\n",
            "        it : O\n",
            "      snow : B-condition_description\n",
            "  tomorrow : B-timeRange\n",
            "        in : O\n",
            "        Sa : B-city\n",
            "       ##c : I-city\n",
            "     ##lay : I-city\n",
            "         ? : O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "t9eDb70OLWvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56f81a1-818f-4a67-e3b2-df5cdb85cdfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Intent: PlayMusic\n",
            "## Slots:\n",
            "         I : O\n",
            "     would : O\n",
            "      like : O\n",
            "        to : O\n",
            "    listen : O\n",
            "        to : O\n",
            "        An : B-album\n",
            "     ##ima : I-album\n",
            "        by : O\n",
            "      Thom : B-artist\n",
            "      York : I-artist\n",
            "       ##e : I-artist\n",
            "         . : O\n"
          ]
        }
      ],
      "source": [
        "conduct_nlu(\"I would like to listen to Anima by Thom Yorke.\",\n",
        "                 tokenizer, joint_model, intent_names, slot_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "uxuDGln1KVh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate the joint NLU over the test set using the following standard evaluation metrics:  \n",
        "\n",
        "*   Intent classification measure: accuracy\n",
        "*   Slot filling measure: span-based F1, recall, precision\n",
        "*   Joint measure: semantic accuracy\n",
        "\n",
        "\n",
        "\n",
        "Remarks:\n",
        "\n",
        "\n",
        "*   For the **span-based slot F1/precision/recall**, a span (sometimes called a chunk) refers to a sequence of words labelled from the same meta-class of the slot, e.g., the labeling of `B-city I-city I-city` across three words is a span of meta-class slot `city`. A slot span is correct only if it is an exact match of the corresponding ground truth slot span. Thus, we can define at the span level that: the **precision** is the percentage of slot spans found by the NLU model that are correct, i.e., # of slot spans correctly detected (TP) / # of total slot spans detected (TP+FP); the **recall** is the percentage of slot spans present in the corpus that are found by the NLU model, i.e., # of slot spans correctly detected (TP) / # of total slot spans (TP+FN). The\n",
        "[conlleval evaluation script](https://github.com/sighsmile/conlleval) is regularly used to calculate the micro-averaged precision, recall and f1.\n",
        "*   F1 = 2 x precision x recall / (precision + recall)\n",
        "*   For the **semantic accuracy**: A sentence is correctly analysed if both the intent is correctly predicted and all the slots (including O labels) are\n",
        "correctly predicted. Semantic accuracy is then the number of correctly analysed sentences divided by the number of sentences.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d9U2pifCPWxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will directly use the seqeval package for sequence labeling evaluation, which supports the BIO format and evaluates based on the conlleval metrics. (For more details, please see: https://pypi.org/project/seqeval/)\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "qwjT8LJgM-_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e0f6bf-16d0-41cb-b3fe-ed7c09c07983"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=6f65f4d206ff00d03cec27e4d69916be86765efe242fa39dc486679a4e6c43a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation functions for joint NLU implemented by monologg from https://github.com/monologg/JointBERT/blob/master/utils.py\n",
        "\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(intent_preds, intent_labels, slot_preds, slot_labels):\n",
        "    assert len(intent_preds) == len(intent_labels) == len(slot_preds) == len(slot_labels)\n",
        "    results = {}\n",
        "    intent_result = get_intent_acc(intent_preds, intent_labels)\n",
        "    slot_result = get_slot_metrics(slot_preds, slot_labels)\n",
        "    sementic_result = get_sentence_frame_acc(intent_preds, intent_labels, slot_preds, slot_labels)\n",
        "\n",
        "    results.update(intent_result)\n",
        "    results.update(slot_result)\n",
        "    results.update(sementic_result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def get_intent_acc(preds, labels):\n",
        "    # Calculate intent accuracy \n",
        "    acc = (preds == labels).mean()\n",
        "    return {\n",
        "        \"intent_acc\": acc\n",
        "    }\n",
        "\n",
        "def get_slot_metrics(preds, labels):\n",
        "    # Calculate slot-based evaluation metrics for slot labeling\n",
        "    assert len(preds) == len(labels)\n",
        "    return {\n",
        "        \"slot_precision\": precision_score(labels, preds),\n",
        "        \"slot_recall\": recall_score(labels, preds),\n",
        "        \"slot_f1\": f1_score(labels, preds)\n",
        "    }\n",
        "\n",
        "def get_sentence_frame_acc(intent_preds, intent_labels, slot_preds, slot_labels):\n",
        "    # Calculate the semantic frame accuracy\n",
        "    \"\"\"For the cases that intent and all the slots are correct (in one sentence)\"\"\"\n",
        "    # Get the intent comparison result\n",
        "    intent_result = (intent_preds == intent_labels)\n",
        "\n",
        "    # Get the slot comparision result\n",
        "    slot_result = []\n",
        "    for preds, labels in zip(slot_preds, slot_labels):\n",
        "        assert len(preds) == len(labels)\n",
        "        one_sent_result = True\n",
        "        for p, l in zip(preds, labels):\n",
        "            if p != l:\n",
        "                one_sent_result = False\n",
        "                break\n",
        "        slot_result.append(one_sent_result)\n",
        "    slot_result = np.array(slot_result)\n",
        "\n",
        "    sementic_acc = np.multiply(intent_result, slot_result).mean()\n",
        "    return {\n",
        "        \"sementic_frame_acc\": sementic_acc\n",
        "    }"
      ],
      "metadata": {
        "id": "E8wuoNa3K-3u"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the prediction logits for test set\n",
        "s_logits, i_logits = joint_model.predict(encoded_test)\n",
        "\n",
        "# Create the mapping dictionary from slot index to corresponding labels - we will use the BIO label for calculating the slot-based F1 score\n",
        "slot_id2label = {v:k for k,v in slot_map.items()}\n",
        "\n",
        "# Get the predicted slot labels and ground truth slot labels - the special tokens and paddings are ignored\n",
        "slot_predict_list=[[] for _ in range(slot_test.shape[0])]\n",
        "slot_label_list=[[] for _ in range(slot_test.shape[0])]\n",
        "for i in range(slot_test.shape[0]):\n",
        "  for j in range(slot_test.shape[1]):\n",
        "    if slot_test[i][j] != slot_map['[PAD]']:\n",
        "      slot_label_list[i].append(slot_id2label[slot_test[i][j]])\n",
        "      slot_predict_list[i].append(slot_id2label[np.argmax(s_logits[i][j])])\n",
        "\n",
        "# Get the predicted intent ids - we can directly compare the predicted id with the ground truth id for calculating the accuracy\n",
        "intent_predict_list = np.argmax(i_logits, axis=1)"
      ],
      "metadata": {
        "id": "Q4ryDyJQHs8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab2f965-0ede-4df3-9b28-7fad45809628"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 7s 122ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = compute_metrics(intent_predict_list, intent_test, slot_predict_list, slot_label_list)\n",
        "evaluation_results"
      ],
      "metadata": {
        "id": "bqGVNS8DNHL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6ef692-0950-4d42-89b4-fd0410cb0123"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent_acc': 0.9914285714285714,\n",
              " 'slot_precision': 0.951113525258012,\n",
              " 'slot_recall': 0.9605046626439934,\n",
              " 'slot_f1': 0.9557860262008733,\n",
              " 'sementic_frame_acc': 0.8971428571428571}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwxmkkUQhfld"
      },
      "source": [
        "#Sec.3 Extension: Applying Joint NLU to In-game Toxicity Detection ðŸŽ®"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVzz8dwLEfgA"
      },
      "source": [
        "The [CONDA dataset](https://github.com/usydnlp/CONDA) is a novel in-game toxic language detection dataset released by the USYDNLP Group (Details can be found in their [ACL paper](https://aclanthology.org/2021.findings-acl.213.pdf)). It consists of 45K utterances from 12K conversations from the chat logs of 1.9K completed Dota 2 matches. Unlike the common sentence-level toxic language detection dataset, CONDA provides dual-level annotation that enables **joint intent classification and slot filling** analysis (borrowed from the joint NLU domain) to pursue better toxic language detection. Thus, we can directly apply jointBert to CONDA for toxic language detection, utilizing their dual-level annotation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C9jnBcJHDlO"
      },
      "source": [
        "We will use the CONDA dataset provided by USYDNLP. The following code downloads the CONDA dataset and the saved model into the 'WWW2023-SLU-data' folder as before.\n",
        "\n",
        "The original dataset provids the splits of 26921/8974/8974 utterances for train/dev/test sets, which can also be downloaded from their [official github](https://github.com/usydnlp/CONDA). "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the CONDA data and saved model\n",
        "downloadFiles([[\"WWW2023-SLU-conda.zip\", \"1U02AYmJUhCQCVGvmPCkSjaCYivLgCpbq\"]])\n",
        "!unzip \"WWW2023-SLU-conda.zip\"\n",
        "!rm \"WWW2023-SLU-conda.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lyz5AL3e8GG",
        "outputId": "d6b28f13-3c87-4651-bb48-ab6b1749c5f6"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  WWW2023-SLU-conda.zip\n",
            "   creating: WWW2023-SLU-conda/WWW2023-SLU-data/\n",
            "   creating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/\n",
            "   creating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/dev/\n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/dev/label  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/dev/seq.in  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/dev/seq.out  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/dev/valid_tokens.out  \n",
            " extracting: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/intent_label.txt  \n",
            " extracting: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/slot_label.txt  \n",
            "   creating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/test/\n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/test/label  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/test/seq.in  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/test/seq.out  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/test/tokens.out  \n",
            "   creating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/train/\n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/train/label  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/train/seq.in  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/dataset-conda/train/seq.out  \n",
            "   creating: WWW2023-SLU-conda/WWW2023-SLU-data/jointbert-conda2/\n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/jointbert-conda2/checkpoint  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/jointbert-conda2/jointbert-conda2.data-00000-of-00001  \n",
            "  inflating: WWW2023-SLU-conda/WWW2023-SLU-data/jointbert-conda2/jointbert-conda2.index  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data file for getting utterances."
      ],
      "metadata": {
        "id": "KnIGv7m5gjE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = ROOT_DIR+'/WWW2023-SLU-conda/WWW2023-SLU-data/'"
      ],
      "metadata": {
        "id": "pUzl8rqlJ69g"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "WywrEV3WHR56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5080cb6f-3177-43f7-e206-a073691ed78e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wow',\n",
              " 'WTF',\n",
              " 'wpe wpe',\n",
              " 'hahaha',\n",
              " 'wtf',\n",
              " 'i cant [SEPA] play [SEPA] with 4 trash']"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ],
      "source": [
        "# Load utterances\n",
        "train_conda_sents_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/train/seq.in\", \"r\").readlines()]\n",
        "dev_conda_sents_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/dev/seq.in\", \"r\").readlines()]\n",
        "test_conda_sents_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/test/seq.in\", \"r\").readlines()]\n",
        "# Short text is the nature of in-game chat\n",
        "train_conda_sents_origin[:6]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data file for getting utterance level intent labels. The dataset is annotated with the following 4 types of intents:\n",
        "\n",
        "\n",
        "*   **E** (**E**xplicit toxicity)\n",
        "*   **I** (**I**mplicit toxicity)\n",
        "*   **A** (**A**ction)\n",
        "*   **O** (**O**ther)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EFnx6RIhgnrw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "pGIgTXzqO4mQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df4d2e8-0057-45c4-83d0-fb753b27ff54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['E', 'O', 'O', 'A', 'I']"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ],
      "source": [
        "# Load intents\n",
        "train_conda_intents_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/train/label\", \"r\").readlines()]\n",
        "dev_conda_intents_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/dev/label\", \"r\").readlines()]\n",
        "test_conda_intents_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/test/label\", \"r\").readlines()]\n",
        "train_conda_intents_origin[5:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the data file for getting token-level slot labels. The dataset is annotated with the following 6 types of slots:\n",
        "\n",
        "\n",
        "*   **T** (**T**oxicity)\n",
        "*   **C** (**C**haracter)\n",
        "*   **D** (**D**otaspecific)\n",
        "*   **S** (game **S**lang)\n",
        "*   **P** (**P**ronoun)\n",
        "*   **O** (**O**ther)\n",
        "\n",
        "The consecutive utterances by a single user within a conversation is merged together into one utterance and separated using a special token [SEPA]."
      ],
      "metadata": {
        "id": "S0NgPG3xhLEK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "JChfgJ9QP2Da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8305b04-6c4e-49fe-f7ed-3100f8875970"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['P O SEPA O SEPA O O O', 'O', 'O', 'S SEPA S P O S SEPA O', 'S S']"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ],
      "source": [
        "# Load slots\n",
        "train_conda_slots_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/train/seq.out\", \"r\").readlines()]\n",
        "dev_conda_slots_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/dev/seq.out\", \"r\").readlines()]\n",
        "test_conda_slots_origin=[d.strip() for d in open(DATA_DIR+\"dataset-conda/test/seq.out\", \"r\").readlines()]\n",
        "train_conda_slots_origin[5:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "sTqZ7-OUbWYi"
      },
      "outputs": [],
      "source": [
        "def remove_empty(sents_origin, slots_origin, intents_origin):\n",
        "  conda_sents=[]\n",
        "  conda_slots=[]\n",
        "  conda_intents=[]\n",
        "  for sent, slot, intent in zip(sents_origin, slots_origin, intents_origin):\n",
        "    if len(sent.split())<1:\n",
        "      continue \n",
        "    conda_sents.append(sent)\n",
        "    conda_slots.append(slot)\n",
        "    conda_intents.append(intent)\n",
        "  return conda_sents, conda_slots, conda_intents\n",
        "\n",
        "# remove those data with empty value\n",
        "train_conda_sents, train_conda_slots, train_conda_intents = remove_empty(train_conda_sents_origin, train_conda_slots_origin, train_conda_intents_origin)\n",
        "dev_conda_sents, dev_conda_slots, dev_conda_intents = remove_empty(dev_conda_sents_origin, dev_conda_slots_origin, dev_conda_intents_origin)\n",
        "test_conda_sents, test_conda_slots, test_conda_intents = remove_empty(test_conda_sents_origin, test_conda_slots_origin, test_conda_intents_origin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pdq6FaVSV7Y"
      },
      "source": [
        "Now, let's load the pre-trained tokenizer (if you've already run the Sec.1 and Sec.2, you can skip it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "C1U88esTLDiU"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# We're using the tokenizer from the 'bert-base-cased' pretrained model\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "bN4eLtz_MY_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "f7c84ffb-0295-4f7a-bfb7-726aefaeceae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check the sequence length distribution after encoding into the BERT-formatted tokenized sequence\n",
        "train_sequence_lengths = [len(tokenizer.encode(text))\n",
        "                          for text in train_conda_sents]\n",
        "plt.hist(train_sequence_lengths, bins=30)\n",
        "plt.title(f\"max sequence length: {max(train_sequence_lengths)}\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utdf-0NDS8uX"
      },
      "source": [
        "Encoding the dataset with Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "CejxzGXaSuUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b751b57-a1c4-4e4f-dd11-f64e092e8806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101,   192,  4064, ...,     0,     0,     0],\n",
              "       [  101,   160, 22169, ...,     0,     0,     0],\n",
              "       [  101,   192,  3186, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,   138,  3048, ...,     0,     0,     0],\n",
              "       [  101,  1285,  1358, ...,     0,     0,     0],\n",
              "       [  101,   144,  1403, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def encode_dataset(tokenizer, text_sequences, max_length):\n",
        "    token_ids = np.zeros(shape=(len(text_sequences), max_length),\n",
        "                         dtype=np.int32)\n",
        "    for i, text_sequence in enumerate(text_sequences):\n",
        "        encoded = tokenizer.encode(text_sequence)\n",
        "        if len(encoded)>max_length:\n",
        "            token_ids[i, :] = encoded[:max_length]\n",
        "        else:\n",
        "            token_ids[i, 0:len(encoded)] = encoded\n",
        "    attention_masks = (token_ids != 0).astype(np.int32)\n",
        "    return {\"input_ids\": token_ids, \"attention_mask\": attention_masks}\n",
        "\n",
        "# Encode the training set\n",
        "# Here we use 50 as our max sequence length for simplicity\n",
        "encoded_train = encode_dataset(tokenizer, train_conda_sents, 50)\n",
        "\n",
        "# The converted result is a padded numpy array of integers that has shape (data_size, max_length), i.e., (26087, 175) in this case.\n",
        "# As you can see all the 0s in the end means padding\n",
        "encoded_train[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "TYj7JCYKWh7J"
      },
      "outputs": [],
      "source": [
        "# Similarly, let's encode the validation and test sets\n",
        "encoded_valid = encode_dataset(tokenizer, dev_conda_sents, 50)\n",
        "encoded_test = encode_dataset(tokenizer, test_conda_sents, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRtDjWVcWolC"
      },
      "source": [
        "Encoding the Intent Classification Targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "lB-WgeadWqeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707a3ba8-dead-43c0-9fe7-0bddee009de6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'E', 'I', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ],
      "source": [
        "intent_names=[d.strip() for d in open(DATA_DIR+\"dataset-conda/intent_label.txt\",'r').readlines()]\n",
        "intent_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "OT9doUojW7tI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65632cb-c8e7-4071-bda4-a2a862ce8799"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 0, 'E': 1, 'I': 2, 'O': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ],
      "source": [
        "intent_map = dict((label, idx) for idx, label in enumerate(intent_names))\n",
        "intent_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "-yS8WXUkXcRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d08ea65-30a2-4c2e-ac23-cd09b0529be8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, ..., 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ],
      "source": [
        "# Get the mapped intent labels for training set\n",
        "intent_train = np.array([intent_map[k] for k in train_conda_intents])\n",
        "intent_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "_p-P12W-XrrW"
      },
      "outputs": [],
      "source": [
        "# Similarly, get the mapped intent labels for validation and test set\n",
        "intent_dev = np.array([intent_map[k] for k in dev_conda_intents])\n",
        "intent_test = np.array([intent_map[k] for k in test_conda_intents])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESCh6srzX-lg"
      },
      "source": [
        "Encoding the Slot Filling Targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "6Svdx06pYIR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a142e63-8bfd-4a6a-b19f-73b7c4c58795"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C', 'D', 'O', 'P', 'S', 'SEPA', 'T']"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ],
      "source": [
        "slot_all=[d.strip() for d in open(DATA_DIR+\"dataset-conda/slot_label.txt\",'r').readlines()]\n",
        "slot_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "NTueo8gmYAL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d911ad4-ee51-422d-a7ca-44e0ab9b8c89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0, 'C': 1, 'D': 2, 'O': 3, 'P': 4, 'S': 5, 'SEPA': 6, 'T': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ],
      "source": [
        "slot_names = [\"[PAD]\"]\n",
        "slot_names += slot_all\n",
        "slot_map = {}\n",
        "for label in slot_names:\n",
        "    slot_map[label] = len(slot_map)\n",
        "# We add the special slot label [PAD] with the corresponding index of 0\n",
        "slot_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "cudb2EotYTNu"
      },
      "outputs": [],
      "source": [
        "def encode_token_labels(text_sequences, slot_names, tokenizer, slot_map,\n",
        "                        max_length):\n",
        "    encoded = np.zeros(shape=(len(text_sequences), max_length), dtype=np.int32)\n",
        "    for i, (text_sequence, word_labels) in enumerate(zip(text_sequences, slot_names)):\n",
        "        encoded_labels = []\n",
        "        for word, word_label in zip(text_sequence.split(), word_labels.split()):\n",
        "            tokens = tokenizer.tokenize(word)\n",
        "            encoded_labels.extend([slot_map[word_label]] * len(tokens))\n",
        "        if len(encoded_labels)>max_length-1:\n",
        "            encoded[i, 1:] = encoded_labels[:max_length-1]\n",
        "        else:\n",
        "            encoded[i, 1:len(encoded_labels)+1] = encoded_labels\n",
        "    return encoded\n",
        "\n",
        "\n",
        "slot_train = encode_token_labels(\n",
        "    train_conda_sents, train_conda_slots, tokenizer, slot_map, 50)\n",
        "slot_valid = encode_token_labels(\n",
        "    dev_conda_sents, dev_conda_slots, tokenizer, slot_map, 50)\n",
        "slot_test = encode_token_labels(\n",
        "    test_conda_sents, test_conda_slots, tokenizer, slot_map, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv2NVFHPgmCu"
      },
      "source": [
        "Now, we've had every single piece of data prepared with CONDA (encoded input sequences and both intent and slot labels)! Let's move to our JointBert! ðŸ˜‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "3UWBoiavgo9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb3315c-7d90-4cd2-b1ff-9436b9742a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings. filterwarnings('ignore')\n",
        "from transformers import TFAutoModel\n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "\n",
        "class JointBert(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, intent_num_labels=None, slot_num_labels=None,\n",
        "                 model_name=\"bert-base-cased\", dropout_prob=0.1):\n",
        "        super().__init__(name=\"joint_intent_slot\")\n",
        "        self.bert = TFAutoModel.from_pretrained(model_name)\n",
        "        self.dropout = Dropout(dropout_prob)\n",
        "        self.intent_classifier = Dense(intent_num_labels,\n",
        "                                       name=\"intent_classifier\")\n",
        "        self.slot_classifier = Dense(slot_num_labels,\n",
        "                                     name=\"slot_classifier\")\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        outputs = self.bert(inputs, training=training)\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        # Recap: The first output of the main BERT layer has shape:\n",
        "        # (batch_size, max_length, output_dim)\n",
        "        # This will be used for slot filling\n",
        "        sequence_output = self.dropout(sequence_output, training=training)\n",
        "        slot_logits = self.slot_classifier(sequence_output)\n",
        "\n",
        "        # Recap: The second output of the main BERT layer has shape:\n",
        "        # (batch_size, output_dim)\n",
        "        # and gives a \"pooled\" representation for the full sequence from the\n",
        "        # hidden state that corresponds to the \"[CLS]\" token.\n",
        "        # This will be used for intent classification\n",
        "        pooled_output = self.dropout(pooled_output, training=training)\n",
        "        intent_logits = self.intent_classifier(pooled_output)\n",
        "\n",
        "        return slot_logits, intent_logits\n",
        "\n",
        "# Initialize the JointBert model\n",
        "joint_model = JointBert(\n",
        "    intent_num_labels=len(intent_map), slot_num_labels=len(slot_map))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "Y2ipoEFbgrq4"
      },
      "outputs": [],
      "source": [
        "# Configure the training settings\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=3e-5, epsilon=1e-08)\n",
        "losses = [SparseCategoricalCrossentropy(from_logits=True),\n",
        "          SparseCategoricalCrossentropy(from_logits=True)]\n",
        "metrics = [SparseCategoricalAccuracy('accuracy')]\n",
        "joint_model.compile(optimizer=opt, loss=losses, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "TCGOB6FtgvMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616147fa-18dd-484b-c3fb-1454da486e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "816/816 [==============================] - 334s 383ms/step - loss: 0.4473 - output_1_loss: 0.0755 - output_2_loss: 0.3718 - output_1_accuracy: 0.9785 - output_2_accuracy: 0.8919 - val_loss: 0.3110 - val_output_1_loss: 0.0307 - val_output_2_loss: 0.2803 - val_output_1_accuracy: 0.9907 - val_output_2_accuracy: 0.9187\n",
            "Epoch 2/2\n",
            "816/816 [==============================] - 316s 387ms/step - loss: 0.2791 - output_1_loss: 0.0293 - output_2_loss: 0.2498 - output_1_accuracy: 0.9911 - output_2_accuracy: 0.9249 - val_loss: 0.3079 - val_output_1_loss: 0.0207 - val_output_2_loss: 0.2872 - val_output_1_accuracy: 0.9938 - val_output_2_accuracy: 0.9149\n"
          ]
        }
      ],
      "source": [
        "# Train JointBert model by fine-tuning the pretrained Bert model \n",
        "history = joint_model.fit(encoded_train, (slot_train, intent_train),validation_data=(encoded_valid, (slot_valid, intent_dev)),epochs=2, batch_size=32)\n",
        "\n",
        "# To save the running time, here we will directly load the weights of the model that we've already trained over 2 epochs for demonstration. Uncomment to load the saved model.\n",
        "# If you want to train it yourself, you can use the above code for training using .fit() above - make sure you are using the GPU runtime for faster training\n",
        "#joint_model.load_weights(DATA_DIR+'jointbert-conda2/jointbert-conda2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will directly use the seqeval package for sequence labeling evaluation, which supports the BIO format (For more details, please see: https://pypi.org/project/seqeval/)\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "4iZ_P2cQR2bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407da5ca-ed42-4f87-de78-53401b90912e"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from seqeval) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation functions modified based on joint NLU implemented by monologg from https://github.com/monologg/JointBERT/blob/master/utils.py\n",
        "\n",
        "# Since here the slot is token-based (NOT in BIO format), we will use the normal f1 score based on the paper\n",
        "from sklearn.metrics import f1_score as conda_slot_f1\n",
        "\n",
        "def compute_metrics(intent_preds, intent_labels, slot_preds, slot_labels):\n",
        "    assert len(intent_preds) == len(intent_labels) == len(slot_preds) == len(slot_labels)\n",
        "    results = {}\n",
        "    intent_result = get_intent_acc(intent_preds, intent_labels)\n",
        "    slot_result = get_slot_metrics(slot_preds, slot_labels)\n",
        "    sementic_result = get_sentence_frame_acc(intent_preds, intent_labels, slot_preds, slot_labels)\n",
        "\n",
        "    results.update(intent_result)\n",
        "    results.update(slot_result)\n",
        "    results.update(sementic_result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def get_intent_acc(preds, labels):\n",
        "    # Calculate intent accuracy \n",
        "    acc = (preds == labels).mean()\n",
        "    return {\n",
        "        \"intent_acc\": acc\n",
        "    }\n",
        "\n",
        "def get_slot_metrics(preds, labels):\n",
        "    # Calculate F1 for slot labeling\n",
        "    preds_all = []\n",
        "    labels_all = []\n",
        "    for i,j in zip(preds,labels):\n",
        "      preds_all.extend(i)\n",
        "      labels_all.extend(j)\n",
        "\n",
        "    assert len(preds) == len(labels)\n",
        "    return {\n",
        "        \"slot_f1\": conda_slot_f1(labels_all, preds_all, average='micro')\n",
        "    }\n",
        "\n",
        "def get_sentence_frame_acc(intent_preds, intent_labels, slot_preds, slot_labels):\n",
        "    # Calculate the semantic frame accuracy\n",
        "    \"\"\"For the cases that intent and all the slots are correct (in one sentence)\"\"\"\n",
        "    # Get the intent comparison result\n",
        "    intent_result = (intent_preds == intent_labels)\n",
        "\n",
        "    # Get the slot comparision result\n",
        "    slot_result = []\n",
        "    for preds, labels in zip(slot_preds, slot_labels):\n",
        "        assert len(preds) == len(labels)\n",
        "        one_sent_result = True\n",
        "        for p, l in zip(preds, labels):\n",
        "            if p != l:\n",
        "                one_sent_result = False\n",
        "                break\n",
        "        slot_result.append(one_sent_result)\n",
        "    slot_result = np.array(slot_result)\n",
        "\n",
        "    sementic_acc = np.multiply(intent_result, slot_result).mean()\n",
        "    return {\n",
        "        \"sementic_frame_acc\": sementic_acc\n",
        "    }"
      ],
      "metadata": {
        "id": "ltmh8WbOR2bl"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the prediction logits for test set\n",
        "s_logits, i_logits = joint_model.predict(encoded_test)\n",
        "\n",
        "\n",
        "# Get the predicted slot index and ground truth slot index - both paddings and label O are ignored (according to the original paper of CONDA)\n",
        "slot_predict_list=[[] for _ in range(slot_test.shape[0])]\n",
        "slot_label_list=[[] for _ in range(slot_test.shape[0])]\n",
        "for i in range(slot_test.shape[0]):\n",
        "  for j in range(slot_test.shape[1]):\n",
        "    if slot_test[i][j] not in [slot_map['[PAD]'],slot_map['O']]:\n",
        "      slot_label_list[i].append(slot_test[i][j])\n",
        "      slot_predict_list[i].append(np.argmax(s_logits[i][j]))\n",
        "    \n",
        "\n",
        "# Get the predicted intent ids - we can directly compare the predicted id with the ground truth id for calculating the accuracy\n",
        "intent_predict_list = np.argmax(i_logits, axis=1)"
      ],
      "metadata": {
        "id": "ocFVsrAjR2bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac148f1b-2df9-4305-ee82-e3cff772fbfd"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "272/272 [==============================] - 31s 103ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = compute_metrics(intent_predict_list, intent_test, slot_predict_list, slot_label_list)\n",
        "evaluation_results"
      ],
      "metadata": {
        "id": "CfvkvsGgR2bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773b203a-6e54-4334-efad-8fd4cda7427c"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent_acc': 0.9119944852941176,\n",
              " 'slot_f1': 0.9382778285390215,\n",
              " 'sementic_frame_acc': 0.8193933823529411}"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrO7D6TsayUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}